{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df35083",
   "metadata": {},
   "source": [
    "# Project 2: UFO Sightings in Wyoming and Yellowstone National Park Visitation\n",
    "\n",
    "## Group 4: Jacob Douthett and Sam Espe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31283256",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "The goal of this project is to practice implementing the Extract-Transform-Load (ETL) process. We chose to use data on reports of UFO sightings (source: https://www.kaggle.com/datasets/NUFORC/ufo-sightings?resource=download) and the yearly visitor count at Yellowstone National Park in Wyoming (source: https://data.world/nps/yellowstone-np). We limited the UFO sightings to those within the state of Wyoming to create a comparable data set. To perform the ETL process, we used Pandas in a Jupyter Notebook, PostgreSQL as the database software, and modules from SQLAlchemy to connect the two entities. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dba8555",
   "metadata": {},
   "source": [
    "### Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d521b12",
   "metadata": {},
   "source": [
    "We started by importing the dependencies we need to complete the project. We imported the Pandas library (using the common alias `pd`), as this will be our main tool to reduce, clean, and reorganize our data to load into our database. We also imported `create_engine` and `inspect` from SQLAlchemy, as we will need these methods to communicate with our PostgreSQL database. Finally, we imported information from the `config.py` file to construct the connection string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11c218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, inspect\n",
    "from config import postgres_db_name, postgres_password, postgres_port, postgres_host"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2516c4",
   "metadata": {},
   "source": [
    "Next, we used Pandas to read the data from the CSV files (located in the `Resources` folder) into dataframes. We loaded the UFO data into `ufo_df` and the Yellowstone National Park visitation data into `yellowstone_df`. We used `.head()` on each dataframe to preview the data, and to verify that it loaded correctly. \n",
    "\n",
    "The Jupyter Notebook returned a warning for the UFO dataframe that columns 5 and 9 have mixed data types. Column 9 (`latitude`) is not data that we were interested in for the final database, so the mixed data type is irrelevant. Column 5 (`duration (seconds)`) is part of the final database, and we addressed the data type mismatch later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9978c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data into dataframes\n",
    "\n",
    "ufo_file = \"Resources/ufo_data_scrubbed.csv\"\n",
    "ufo_df = pd.read_csv(ufo_file)\n",
    "\n",
    "ufo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f853e0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "yellowstone_file = \"Resources/Yellowstone_Annual_Park_Recreation_Visitation_1904-2018.csv\"\n",
    "yellowstone_df = pd.read_csv(yellowstone_file)\n",
    "\n",
    "yellowstone_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38abb8fa",
   "metadata": {},
   "source": [
    "### Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81a0299",
   "metadata": {},
   "source": [
    "Our next step was to transform the data. For the UFO data, we wanted to end up with a dataframe of complete entries (no NaNs) that only contains UFO reports from Wyoming, USA. For the Yellowstone National Park visitation data, we wanted to end up with a database that contains years and the corresponding number of visitors for that year.\n",
    "\n",
    "The UFO data set required more work to refine it, so we started with that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af167c17",
   "metadata": {},
   "source": [
    "#### Transform UFO data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3c6bba",
   "metadata": {},
   "source": [
    "We started by removing any entries from the worldwide data set that contain any NaN values. This ensured that our end product contains complete data for each report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bc6a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop entries that have NaN values\n",
    "\n",
    "ufo_no_nan_states = ufo_df.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbca6a5",
   "metadata": {},
   "source": [
    "We were only interested in reports that come from Wyoming, so that we could compare the frequency of UFO reports in Wyoming to the visitor counts to Yellowstone National Park, located in Wyoming. The data set abbreviates Wyoming to 'wy', so we used Pandas to filter the dataframe to only include reports where the state is 'wy'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1061e9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter UFO dataframe to include only entries from Wyoming\n",
    "\n",
    "ufos_wyoming_df = ufo_no_nan_states[ufo_no_nan_states[\"state\"].str.contains(\"wy\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28df0da4",
   "metadata": {},
   "source": [
    "In working with the data within the `datetime` column, we discovered that two records had invalid datetimes, which prevented us from continuing. The problem with both entries was that the time was recorded as \"24:00\". Pandas only recognizes hours from 0 to 23, and that caused the code not to work. We made the decision to remove the two offending records, since it seemed improper to edit the data itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d564a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping indices #6496 and #37861 because the datetime objects are invalid\n",
    "\n",
    "ufos_wyoming_df = ufos_wyoming_df.drop(index=6496)\n",
    "ufos_wyoming_df = ufos_wyoming_df.drop(index=37861)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdba5406",
   "metadata": {},
   "source": [
    "To compare the UFO reports to the Yellowstone National Park visitation data, we created a new column that contained the year of the UFO sighting report. This way, an analyst could easily correlate reports to the visitation data of that year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3741a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year from datetime object, save it to its own series\n",
    "\n",
    "ufos_wyoming_df['year'] = pd.DatetimeIndex(ufos_wyoming_df['datetime']).year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dc0364",
   "metadata": {},
   "source": [
    "For the final database, we did not want to include all of the data for each entry that the original data set provided. We decided only to include the year of the report, the city and state of the sighting, the duration of the event in seconds, the shape of the UFO, and the observer's comments. To obtain a dataframe with only the desired information, we dropped the rest of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ae441b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter columns of UFO dataframe to include only: Year, City, State, Duration (seconds), Shape, and Comments\n",
    "\n",
    "ufos_wy_for_db = ufos_wyoming_df.copy()\n",
    "\n",
    "ufos_wy_for_db = ufos_wy_for_db.drop(labels=[\"datetime\", \"country\", \"duration (hours/min)\", \"date posted\", \"latitude\", \"longitude \"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0227213c",
   "metadata": {},
   "source": [
    "We renamed some of the columns to clarify their meaning, as well as to make them conform to proper naming conventions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3343b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "\n",
    "ufos_wy_for_db = ufos_wy_for_db.rename(columns={\"duration (seconds)\":\"duration_seconds\", \"shape\":\"ufo_shape\", \"comments\":\"sighting_description\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d31bcb",
   "metadata": {},
   "source": [
    "Here, we fix the data type of the `duration_seconds` column. There was originally a combination of integers and floating point numbers. We cast all of the data in the column as floating point numbers so we did not lose any of the original information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f6bce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix duration data type â€” make the whole series floating points instead of strings.\n",
    "\n",
    "ufos_wy_for_db.duration_seconds = ufos_wy_for_db.duration_seconds.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efdbc91",
   "metadata": {},
   "source": [
    "#### Transform Yellowstone Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fa11a4",
   "metadata": {},
   "source": [
    "We started by removing the `totalrecreationvisitors` column. This column contained the sum of the number of visitors for all of the years where attendance data was collected, and is irrelevant to the database we want to create. This number can easily be calculated in the SQL database if the analyst needs it in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569dad60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter columns of Yellowstone dataframe to include only Year and Recreation Visitors\n",
    "\n",
    "yellowstone_df = yellowstone_df.drop(labels = \"totalrecreationvisitors\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d6415f",
   "metadata": {},
   "source": [
    "We renamed the `recreationvisitors` column to `visitor_count` to increase clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61810e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename recreationvisitors column\n",
    "\n",
    "yellowstone_df = yellowstone_df.rename(columns={\"recreationvisitors\":\"visitor_count\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824ac534",
   "metadata": {},
   "source": [
    "In our database, we wanted to have the `visitor_count` data be integers so an analyst can do numerical analysis. Each entry started as a string, and the integer data type does not tolerate a grouping marker. To successfully cast the data as integers, we removed the commas from each entry in the column. We then were able to cast the column as an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c52319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove commas from visitor_counts so we can turn into integer\n",
    "\n",
    "yellowstone_df.visitor_count = yellowstone_df.visitor_count.str.replace(\",\", \"\")\n",
    "\n",
    "# Change data type of visitor_count column from string to integer\n",
    "\n",
    "yellowstone_df.visitor_count = yellowstone_df.visitor_count.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884ad5f0",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff48c6fb",
   "metadata": {},
   "source": [
    "The final phase of the project is to load the transformed data into the database. We used PostgreSQL as our database software. We created the SQL database and tables separately using PostgreSQL. At this point, we were ready to connect the Jupyter Notebook to the PostgreSQL database and load our data from the Pandas dataframes into the database tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333409ea",
   "metadata": {},
   "source": [
    "#### Connect to PostgreSQL database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f395497",
   "metadata": {},
   "source": [
    "We started by reading the values from the `config.py` file into variables. We used these variables to create the connection string to access PostgreSQL with SQLAlchemy. Since `config.py` is included in the `.gitignore` file, the user's password is not exposed. Using the external file to hold the variable parameters allows the user to change them all in one location, and then use the Jupyter Notebook to implement any changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbf6d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data from config.py as variables to use in connection string\n",
    "password = postgres_password\n",
    "port = postgres_port\n",
    "host = postgres_host\n",
    "db_name = postgres_db_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1158a1cd",
   "metadata": {},
   "source": [
    "We used an f-string to add the variable values to the connection string, and used SQLAlchemy's `create_engine` method to form the connection to the PostgreSQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e95972a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create connection string\n",
    "conn_string = f\"postgresql://postgres:{password}@{host}:{port}/{db_name}\"\n",
    "\n",
    "engine = create_engine(conn_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8a0c27",
   "metadata": {},
   "source": [
    "Once the Jupyter Notebook and the database were connected, we wanted to check that the connection works. To do that, we used the inspect method to get the table names from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653e8e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that the connection works\n",
    "inspector = inspect(engine)\n",
    "\n",
    "inspector.get_table_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ea7080",
   "metadata": {},
   "source": [
    "#### Load UFO data into SQL database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4619ee68",
   "metadata": {},
   "source": [
    "We used Pandas' capabilities to write the `ufos_wy_for_db` dataframe to the `ufo_sightings` table in the PostgreSQL database. We did not want to include the dataframe index into our database, so we set `index = False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37e6c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ufos_wy_for_db.to_sql(name = \"ufo_sightings\", con = engine, if_exists = \"append\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097e8624",
   "metadata": {},
   "source": [
    "#### Load Yellowstone data into SQL database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817c6918",
   "metadata": {},
   "source": [
    "We used the same process to write the contents of the `yellowstone_df` dataframe to the `yellowstone` table in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb1f6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "yellowstone_df.to_sql(name = \"yellowstone\", con = engine, if_exists = \"append\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
